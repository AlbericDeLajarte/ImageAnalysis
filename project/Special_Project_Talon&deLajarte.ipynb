{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2020:][iapr2020] Project ‒ Special Project¶\n",
    "**Author:** Quentin Talon & Albéric de Lajarte  \n",
    "**Due date:** 28.05.2020  \n",
    "[iapr2018]: https://github.com/LTS5/iapr-2020\n",
    "\n",
    "## Extract datas\n",
    "We used pims : `pip install git+https://github.com/soft-matter/pims.git`, `skimage`, `os`, `numpy`, `matplotlib`, `argparse`, `pickle`, `gzip`, `sklearn`, `scipy`, `warnings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='IAPR Special Project : Analyse a video to find it\\'s equation shown by the robot')\n",
    "parser.add_argument('--input', required=False)\n",
    "parser.add_argument('--output', required=False, default=\"out.mp4\")\n",
    "parser.add_argument('-f')#To run flawlessly in jupyter-notebook\n",
    "args = parser.parse_args()\n",
    "print(\"--input {}\".format(args.input))\n",
    "print(\"--output {}\".format(args.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pims\n",
    "import warnings\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "if(args.input is None):\n",
    "    vid = pims.open(os.path.join(data_base_path, 'robot_parcours_1_rotated_300.mp4'))\n",
    "else:\n",
    "    vid = pims.open(args.input)\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "plt.imshow(vid[0])\n",
    "print(vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Still and moving image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "We simply calculate the median along all the images. This reduces the noise and removes the moving object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vid_stack = np.stack(vid, axis=0)\n",
    "background = np.median(vid_stack, axis=0).astype(int)\n",
    "if args.input is None:\n",
    "    plt.figure(figsize = (20,20))\n",
    "    plt.imshow(background)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving part\n",
    "We look at the red color, clean it a bit and look at his position, size and direction.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Few tests.\n",
    "from skimage.morphology import binary_opening, binary_closing, disk, label\n",
    "from skimage.measure import regionprops\n",
    "from skimage.filters import threshold_otsu\n",
    "def red(v, th):\n",
    "    r = v[:,:,0] > threshold_otsu(v[:,:,0])\n",
    "    g = v[:,:,1] < threshold_otsu(v[:,:,1])\n",
    "    b = v[:,:,2] < threshold_otsu(v[:,:,2])\n",
    "    return np.logical_and(r, g, b)\n",
    "col_threshold = 100#How to choose it ???\n",
    "if args.input is None:\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,10))\n",
    "\n",
    "    red_arrow = red(vid[32], col_threshold)\n",
    "    red_arrow_opened = binary_opening(red_arrow, selem=disk(3))\n",
    "\n",
    "    ax[0].imshow(red_arrow)\n",
    "    ax[0].set_title(\"Before opening dif\")\n",
    "    ax[1].imshow(red_arrow_opened)\n",
    "    ax[1].set_title(\"After opening\")\n",
    "    plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had to create a home made rectangle mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skimage.draw import polygon\n",
    "def rect2mask(x0, y0, l_x, l_y, ang, shape):#ang in rad\n",
    "    hyp = 0.5*np.sqrt(l_x**2+l_y**2)\n",
    "    rect_ang = np.arctan(l_x/l_y) + np.pi/2\n",
    "    top_right = (x0+np.cos(ang+rect_ang)*hyp, y0+np.sin(ang+rect_ang)*hyp)\n",
    "    top_left = (x0+np.cos(ang+np.pi-rect_ang)*hyp, y0+np.sin(ang+np.pi-rect_ang)*hyp)\n",
    "    bottom_right = (x0+np.cos(ang-rect_ang)*hyp, y0+np.sin(ang-rect_ang)*hyp)\n",
    "    bottom_left = (x0+np.cos(ang+np.pi+rect_ang)*hyp, y0+np.sin(ang+np.pi+rect_ang)*hyp)\n",
    "    poly_coordinates = np.asarray([top_right, top_left, bottom_left, bottom_right])\n",
    "    rr, cc = polygon(poly_coordinates[:,0], poly_coordinates[:,1], shape=shape)\n",
    "    mask = np.zeros(shape, dtype=bool)\n",
    "    mask[rr, cc, :] = [True, True, True]\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a mask for each frame and apply it on the background for each frame.  \n",
    "So we have an image of the background were we see it's value only at the position of the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def crop_image(img):\n",
    "    mask = img>0\n",
    "    if img.ndim==3:\n",
    "        mask = mask.all(2)\n",
    "    mask0,mask1 = mask.any(0),mask.any(1)\n",
    "    return img[np.ix_(mask1,mask0)][2:-2, 2:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# Find region of the robot\n",
    "trajectory = [regionprops(label(binary_opening(red(v, col_threshold), disk(2))))[0] for v in vid]\n",
    "trajectory_mask = [rect2mask(*point.centroid, point.major_axis_length, point.minor_axis_length, point.orientation, vid.frame_shape) for point in trajectory]\n",
    "\n",
    "# Mask the part of the backgroung that is not in this region\n",
    "hidden_background = [np.multiply(background,t) for t in trajectory_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo\n",
    "### Trouver les boxes qui contiennent les symboles DONE\n",
    "En analysant le background.\n",
    "### Lister les boxes qui sont couvertes par le robot DONE\n",
    "La première box sera de type **numéro**, la 2ème de type **opérateur**, etc.\n",
    "### Analyser le contenu des boxes Albéric\n",
    "Par MLP entraitné sur MNIST avec rotation. Par d'autres types de descriptors pour les opérateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Si mask area mask[bb_corners] == 1, tout couvert\n",
    "def covered(mask, bbox):\n",
    "    count_covered_edges = 0\n",
    "    for r in [bbox[0], bbox[2]]:\n",
    "        for c in [bbox[1], bbox[3]]:\n",
    "            count_covered_edges = count_covered_edges + mask[r, c]\n",
    "    return count_covered_edges >= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the regions of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import binary_opening, binary_closing, binary_erosion, binary_dilation, disk, label\n",
    "from skimage.measure import regionprops\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "bk_g = color.rgb2gray(background) #background gray\n",
    "bk_b = np.where(color.rgb2gray(bk_g) < 1.4*threshold_otsu(bk_g), 1, 0) #background binary\n",
    "if args.input is None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(bk_b)\n",
    "    plt.show(block=False)\n",
    "bk_bb = binary_dilation(bk_b, disk(3)) #background with consolidated objects\n",
    "bk_bb_label = label(bk_bb) #Labelise\n",
    "bk_bb_regionprops = regionprops(bk_bb_label) #Measure the image\n",
    "valid_boxes = [] #Keep the regionprops we wanted\n",
    "for b in bk_bb_regionprops:\n",
    "    if(b.bbox_area>200 and b.bbox_area < 1100): #If the bounding box is bigger than 50 and smaller than 700, it's a sign\n",
    "        valid_boxes.append(b)\n",
    "\n",
    "if args.input is None:\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(bk_g, cmap='gray')\n",
    "    for b in valid_boxes:\n",
    "        minr, minc, maxr, maxc = b.bbox\n",
    "        rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                  fill=False, edgecolor='red', linewidth=1)\n",
    "        ax.add_patch(rect)\n",
    "print(\"We have {} valid_boxes\".format(len(valid_boxes)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the order they get selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(trajectory_mask[0].shape)\n",
    "used_bb=dict()\n",
    "for i, tm in enumerate(trajectory_mask):\n",
    "    for bb in valid_boxes:\n",
    "        if(covered(tm[:,:,0], bb.bbox)): #If the bounding box is covered\n",
    "            if(bb not in list(used_bb.values())[-2:]):#Add it to the list of used bounding boxes\n",
    "                used_bb[i] = bb\n",
    "print(\"We have {} used bounding_boxes\".format(len(used_bb)))\n",
    "if args.input is None:\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    ax.imshow(bk_g, cmap='gray')\n",
    "    for i, bb in enumerate(used_bb):\n",
    "        minr, minc, maxr, maxc = used_bb[bb].bbox\n",
    "        rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                  fill=False, edgecolor='red', linewidth=1)\n",
    "        ax.text(maxc,maxr, i)\n",
    "        ax.add_patch(rect)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dict of used frame, with all the needed informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "used_frame = []\n",
    "\n",
    "for i, bb in enumerate(used_bb):\n",
    "    frame = {\"frame_number\": bb,\n",
    "             \"type\": \"number\" if(i%2==0) else \"operator\",  \n",
    "            }\n",
    "    frame[\"bbox\"] = used_bb[bb].bbox\n",
    "    frame[\"rgb_image\"] = background[used_bb[bb].bbox[0]:used_bb[bb].bbox[2], used_bb[bb].bbox[1]:used_bb[bb].bbox[3]]\n",
    "    frame[\"segmented\"] = np.where(rgb2gray(frame[\"rgb_image\"]) < threshold_otsu(rgb2gray(frame[\"rgb_image\"])), 255, 0)\n",
    "    frame[\"labeled\"] = label(frame[\"segmented\"])\n",
    "    frame[\"region\"] = regionprops(frame[\"labeled\"], intensity_image=frame[\"segmented\"] )\n",
    "    used_frame.append(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classifier\n",
    "### 1. Number classification: MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fourier(list_image):\n",
    "    contour_images = [find_contours(np.where(im > threshold_otsu(im), 255, 0), 1)[0] for im in list_image]\n",
    "    complex_image = [[np.complex(x[1], x[0]) for x in X] for X in contour_images]\n",
    "    FFT_images = [np.abs(np.fft.fft(x, n = 200)[1:]) for x in complex_image]\n",
    "    \n",
    "    return FFT_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def accuracy(model, data_test_flat, label_test):\n",
    "    predicted = np.argmax(model.predict_proba(data_test_flat), 1)\n",
    "    score =  sum(predicted == label_test) / len(data_test_flat)\n",
    "    print(\"Our score {} of correct answers\".format(100*score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load classic MNIST\n",
    "import gzip\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "def extract_data(filename, image_shape, image_number):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(np.prod(image_shape) * image_number)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(image_number, image_shape[0], image_shape[1])\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, image_number):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * image_number)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels\n",
    "\n",
    "if not os.path.isfile('pickle_MNIST_model.pkl'):\n",
    "    \n",
    "    image_shape = (28, 28)\n",
    "    train_set_size = 60000\n",
    "    test_set_size = 10000\n",
    "\n",
    "    data_MNIST = os.path.join(data_base_path, \"MNIST\")\n",
    "\n",
    "    train_images_path = os.path.join(data_MNIST, 'train-images-idx3-ubyte.gz')\n",
    "    train_labels_path = os.path.join(data_MNIST, 'train-labels-idx1-ubyte.gz')\n",
    "    test_images_path = os.path.join(data_MNIST, 't10k-images-idx3-ubyte.gz')\n",
    "    test_labels_path = os.path.join(data_MNIST, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "    train_images = extract_data(train_images_path, image_shape, train_set_size)\n",
    "    test_images = extract_data(test_images_path, image_shape, test_set_size)\n",
    "    train_labels = extract_labels(train_labels_path, train_set_size)\n",
    "    test_labels = extract_labels(test_labels_path, test_set_size)\n",
    "\n",
    "    train_images = train_images[train_labels != 9]\n",
    "    train_labels = train_labels[train_labels != 9]\n",
    "    test_images = test_images[test_labels != 9]\n",
    "    test_labels = test_labels[test_labels != 9]\n",
    "\n",
    "    # Compute Fourier of image\n",
    "    Fourier_train = compute_fourier(train_images)\n",
    "    Fourier_test = compute_fourier(test_images)\n",
    "\n",
    "    #--------------------------#\n",
    "    ## Load rotated MNIST\n",
    "    rot_MNIST_test = np.loadtxt('../data/mnist_rotation_new/mnist_all_rotation_normalized_float_test.amat')\n",
    "    rot_MNIST_train = np.loadtxt('../data/mnist_rotation_new/mnist_all_rotation_normalized_float_train_valid.amat')\n",
    "\n",
    "    # Get rid of 9\n",
    "    rot_MNIST_test = rot_MNIST_test[rot_MNIST_test[:,-1] != 9]\n",
    "    rot_MNIST_train = rot_MNIST_train[rot_MNIST_train[:,-1] != 9]\n",
    "\n",
    "    # Save labels in separate list\n",
    "    rot_test_labels = rot_MNIST_test[:,-1]\n",
    "    rot_train_labels = rot_MNIST_train[:,-1]\n",
    "\n",
    "    # Get rid of labels\n",
    "    rot_MNIST_test = rot_MNIST_test[:,:-1]\n",
    "    rot_MNIST_train = rot_MNIST_train[:,:-1]\n",
    "\n",
    "    # Reshape as classic 28*28 image\n",
    "    rot_MNIST_test = rot_MNIST_test.reshape(-1, 28,28)\n",
    "    rot_MNIST_train = rot_MNIST_train.reshape(-1, 28,28)\n",
    "\n",
    "    # Compute Fourier of image\n",
    "    rot_Fourier_test = compute_fourier(rot_MNIST_test)\n",
    "    rot_Fourier_train = compute_fourier(rot_MNIST_train)\n",
    "\n",
    "    # Combine dataset\n",
    "    total_train_images = np.append(Fourier_train,rot_Fourier_train, axis=0)\n",
    "    total_train_labels = np.append(train_labels, rot_test_labels, axis=0)\n",
    "\n",
    "    total_test_images = np.append(Fourier_test,rot_Fourier_test, axis=0)\n",
    "    total_test_labels = np.append(test_labels, rot_train_labels, axis=0)\n",
    "\n",
    "    # Train and save MLP\n",
    "    mlp_adam = MLPClassifier(solver='adam', activation='relu', alpha=1e-4, hidden_layer_sizes=(200,30,20),\n",
    "                             verbose=True, random_state=1, learning_rate_init = 0.0007, max_iter = 400)\n",
    "    mlp_adam.fit(Fourier_train, train_labels)\n",
    "\n",
    "    accuracy(mlp_adam, Fourier_train, train_labels)\n",
    "\n",
    "    # Save to file in the current working directory\n",
    "    with open(\"pickle_MNIST_model.pkl\", 'wb') as file:\n",
    "        pickle.dump(mlp_adam, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of MLP predictor\n",
    "Using the rotation MNIST test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickle_MNIST_model.pkl\", 'rb') as file:\n",
    "    saved_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "if args.input is None:\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(10,8))        \n",
    "    for im, ax in zip(valid_boxes, axes.flatten()):\n",
    "        image_mlp = background[im.bbox[0]:im.bbox[2], im.bbox[1]:im.bbox[3]]\n",
    "        image_mlp = np.where(rgb2gray(image_mlp) < threshold_otsu(rgb2gray(image_mlp)), 255, 0)\n",
    "        image_mlp_flat = np.ravel(resize(image_mlp, (28, 28), anti_aliasing=True, preserve_range=True).astype(int))\n",
    "\n",
    "        image_FFT = compute_fourier([image_mlp])\n",
    "        \n",
    "        ax.imshow(image_mlp, cmap = \"gray\")\n",
    "        result = saved_model.predict_proba(image_FFT)\n",
    "        # Plot ratio of best estimate over 2nd best estimate to show confidence of MLP\n",
    "        #ax.set_title(\"{:0.2f}\".format(np.max(result)/np.max(result[result!=np.max(result)])))\n",
    "        ax.set_title(np.argmax(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Operator classification\n",
    "#### Operator train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct Operator dataset for classification\n",
    "from skimage.transform import ProjectiveTransform\n",
    "from skimage.transform import swirl, rotate\n",
    "from skimage import io\n",
    "\n",
    "if not os.path.isfile('operators_classification.pkl'):\n",
    "    # Attention, file needed \n",
    "    img_operator = io.imread(os.path.join(data_base_path, 'original_operators.png'))\n",
    "    img_operator = np.where(rgb2gray(img_operator) < threshold_otsu(rgb2gray(img_operator)), 255, 0)\n",
    "\n",
    "    img_plus = [img_operator[:,0:347]]*1000\n",
    "    img_moins = [img_operator[:,347*2:347*3]]*1000\n",
    "    img_prod = [img_operator[:,347*4:]]*1000\n",
    "\n",
    "    img_pmp = [img_plus, img_moins, img_prod]\n",
    "\n",
    "    rand_rot = np.random.normal(0, 15, 1000)\n",
    "    rand_swirl = np.random.normal(0, 0.5, 1000)\n",
    "\n",
    "    rand_Xmin = np.round(np.abs(np.random.normal(0, 2.5, 1000))).astype(int)+1\n",
    "    rand_Xmax = np.round(np.abs(np.random.normal(0, 2.5, 1000))).astype(int)+1\n",
    "    rand_Ymin = np.round(np.abs(np.random.normal(0, 2.5, 1000))).astype(int)+1\n",
    "    rand_Ymax = np.round(np.abs(np.random.normal(0, 2.5, 1000))).astype(int)+1\n",
    "\n",
    "    img_pmp_trans = [[ rotate(swirl(resize(img_op, (40,40), preserve_range=True), strength = rand_swirl[i], preserve_range=True), angle = rand_rot[i]) for i, img_op in enumerate(img_op_list)] for img_op_list in img_pmp]\n",
    "\n",
    "    img_pmp_trans = [[ resize(img_op[rand_Xmin[i]:-rand_Xmax[i], rand_Ymin[i]:-rand_Ymax[i]], (28,28), anti_aliasing=True, preserve_range=True).astype(int) for i, img_op in enumerate(img_op_list)] for img_op_list in img_pmp_trans]\n",
    "\n",
    "    img_pmp_trans_region = [[regionprops(label(np.where(img_op > threshold_otsu(img_op), 255, 0)), intensity_image= img_op) for img_op in img_op_list] for img_op_list in img_pmp_trans]\n",
    "    operators_classification = dict()\n",
    "    operators_classification[\"mean_feature\"] = [[np.mean([img_op[0].solidity for img_op in img_op_list]), np.mean([img_op[0].eccentricity for img_op in img_op_list])] for img_op_list in img_pmp_trans_region]\n",
    "    operators_classification[\"var_feature\"] = [[np.var([img_op[0].solidity for img_op in img_op_list]), np.var([img_op[0].eccentricity for img_op in img_op_list])] for img_op_list in img_pmp_trans_region]\n",
    "    with open(\"operators_classification.pkl\", 'wb') as file: # We should dump only the needed things, not the whole 42 Mo\n",
    "        pickle.dump(operators_classification, file)\n",
    "        \n",
    "with open(\"operators_classification.pkl\", 'rb') as file:\n",
    "    operators_classification = pickle.load(file)\n",
    "    \n",
    "mean_feature = operators_classification[\"mean_feature\"]\n",
    "var_feature = operators_classification[\"var_feature\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operator test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct list of operator of the background for testing\n",
    "if args.input is None:\n",
    "    list_operator = []\n",
    "    for frame in used_frame:\n",
    "        if frame[\"type\"] == \"operator\":\n",
    "            if (np.amax(frame[\"labeled\"]))==1: # Operator with only one region need additional work for classification          \n",
    "                list_operator.append(frame) # This is only for training\n",
    "            \n",
    "    # ADDING FAKE MINUS SIGN TO LIST OF OPERATOR\n",
    "    im = valid_boxes[7]\n",
    "    image_mlp = background[im.bbox[0]:im.bbox[2], im.bbox[1]:im.bbox[3]]\n",
    "    image_mlp = resize(image_mlp, (28, 28), anti_aliasing=True, preserve_range=True).astype(int)\n",
    "    image_mlp = np.where(rgb2gray(image_mlp) < threshold_otsu(rgb2gray(image_mlp)), 255, 0)\n",
    "\n",
    "    image_mlp[:8] = np.zeros((8,28))\n",
    "    image_mlp[20:] = np.zeros((8,28))\n",
    "\n",
    "    frame = dict()\n",
    "    frame[\"segmented\"] = image_mlp\n",
    "    frame[\"labeled\"] = label(frame[\"segmented\"])\n",
    "    frame[\"region\"] = regionprops(frame[\"labeled\"], intensity_image=frame[\"segmented\"] )\n",
    "\n",
    "    list_operator.append(frame)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10,8)) \n",
    "    for op, ax in zip(list_operator, axes.flatten()):\n",
    "        ax.imshow(op[\"segmented\"])\n",
    "        ax.set_title(\"Per:{:.2}, Area:{}\".format(op[\"region\"][0].perimeter, op[\"region\"][0].area ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test operator dataset and operator from background with computed mean and variance for mahalanobis classifier\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from numpy.linalg import inv\n",
    "\n",
    "if args.input is None and False:\n",
    "    XX, YY = np.meshgrid(np.linspace(0.5, 1.1, 100), np.linspace(0, 1, 100))\n",
    "    map_feature = np.asarray([[np.argmax([-mahalanobis(np.asarray([x,y]), mean_feat, inv(np.diag(var_feat))) for mean_feat, var_feat in zip(mean_feature, var_feature)]) for x in (XX[0,:])] for y in (YY[:,0])])\n",
    "\n",
    "    fig, axe = plt.subplots(1, 1, figsize=(15,8))\n",
    "\n",
    "    axe.pcolor(XX, YY, map_feature)\n",
    "\n",
    "    axe.scatter([img[0].solidity for img in img_pmp_trans_region[0]], [img[0].eccentricity for img in img_pmp_trans_region[0]], marker = '+', color = 'red')\n",
    "    axe.scatter([img[0].solidity for img in img_pmp_trans_region[1]], [img[0].eccentricity for img in img_pmp_trans_region[1]], marker = '^', color = 'blue')\n",
    "    axe.scatter([img[0].solidity for img in img_pmp_trans_region[2]], [img[0].eccentricity for img in img_pmp_trans_region[2]], marker = 'H', color = 'green')\n",
    "    axe.scatter(list_operator[0][\"region\"][0].solidity, list_operator[0][\"region\"][0].eccentricity, marker = '+', color = 'w', label = '+ operator')\n",
    "    axe.scatter(list_operator[1][\"region\"][0].solidity, list_operator[1][\"region\"][0].eccentricity, marker = 'H', color = 'w', label = '* operator')\n",
    "    axe.scatter(list_operator[2][\"region\"][0].solidity, list_operator[2][\"region\"][0].eccentricity, marker = '^', color = 'w', label = '- operator')\n",
    "    \n",
    "    axe.legend()\n",
    "    axe.set_xlabel(\"solidity\")\n",
    "    axe.set_ylabel(\"eccentricity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 100% correct classification. We can thus use these parameters for classification\n",
    "\n",
    "Using the video we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show result of MLP prediction\n",
    "class_op = [\"+\", \"-\", \"*\", \"=\", \"÷\"]\n",
    "\n",
    "for frame in used_frame:\n",
    "    if frame[\"type\"] == \"number\":\n",
    "        image_mlp_sized = resize(frame[\"segmented\"], (28, 28), anti_aliasing=True, preserve_range=True).astype(int)\n",
    "        image_mlp = compute_fourier([image_mlp_sized])[0]\n",
    "        frame[\"class\"] = np.argmax(saved_model.predict_proba([image_mlp]), 1)[0]\n",
    "        \n",
    "    if frame[\"type\"] == \"operator\":\n",
    "        if (np.amax(frame[\"labeled\"]))>1: \n",
    "            frame[\"class\"] = class_op[np.amax(frame[\"labeled\"]) + 1]\n",
    "        else:\n",
    "            frame[\"class\"] = class_op[np.argmax([-mahalanobis(np.asarray([frame[\"region\"][0].solidity,frame[\"region\"][0].eccentricity]), mean_feat, inv(np.diag(var_feat))) for mean_feat, var_feat in zip(mean_feature, var_feature)])]\n",
    "    \n",
    "    print(\"Class is: \"+ str(frame[\"class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "def ani_frame(frames_list, positions, equation, valid_boxes, used_bb, used_frame):\n",
    "    positions=np.asarray(positions)\n",
    "    mpl.rcParams['savefig.pad_inches'] = 0\n",
    "    fig = plt.figure( frameon=False)\n",
    "    ax = plt.axes([0,0,1,1], frameon=False)\n",
    "    ax.set_aspect('auto')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.autoscale(tight=True)\n",
    "    fig.set_size_inches((vid.frame_shape[1]/100, vid.frame_shape[0]/100))\n",
    "\n",
    "    for bb in valid_boxes:# Plot the valide boxes.\n",
    "        minr, minc, maxr, maxc = bb.bbox\n",
    "        rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                  fill=False, edgecolor='blue', alpha=0.5, linewidth=1)\n",
    "        ax.add_patch(rect)\n",
    "    time_im = ax.imshow(frames_list[0])\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    time_frame_number = ax.text(10,26, 'Frame nº{:02d}'.format(0), fontsize=12, bbox=props)\n",
    "    time_positions, = ax.plot([], [], ls='--', marker='o', markersize=12, color='r', lw=1, alpha=0.5, fillstyle='none')\n",
    "    time_equation = ax.text(10, frames_list[0].shape[0]-20, '', fontsize=12, bbox=props)\n",
    "    for frame in used_frame:\n",
    "        ax.text(frame[\"bbox\"][3], frame[\"bbox\"][2], frame[\"class\"])\n",
    "    def update_img(n):\n",
    "        time_im.set_data(frames_list[n])\n",
    "        time_positions.set_data(positions[0:n+1,1], positions[0:n+1,0])\n",
    "        time_frame_number.set_text('Frame nº{:02d}'.format(n))\n",
    "        time_equation.set_text('Eq: {}'.format(equation[n]))\n",
    "        if n in used_bb.keys():\n",
    "            minr, minc, maxr, maxc = used_bb[n].bbox\n",
    "            rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                      fill=False, edgecolor='red', alpha=1, linewidth=1)\n",
    "            ax.add_patch(rect)\n",
    "        return time_im\n",
    "    #legend(loc=0)\n",
    "    ani = animation.FuncAnimation(fig,update_img,range(len(frames_list)))\n",
    "    writer = animation.writers['ffmpeg'](fps=vid.frame_rate)\n",
    "    ani.save(args.output,writer=writer,dpi=100)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "positions=[t.centroid for t in trajectory]\n",
    "equation=['' for i in range(len(vid))]\n",
    "pivot = 0\n",
    "for frame in used_frame:\n",
    "    if '=' not in str(frame[\"class\"]):\n",
    "        for i in np.arange(pivot, len(vid)):\n",
    "            equation[i] = equation[pivot]\n",
    "        equation[frame[\"frame_number\"]] = equation[pivot]+str(frame[\"class\"])+' '\n",
    "        pivot = frame[\"frame_number\"]\n",
    "    else:\n",
    "        for i in np.arange(frame[\"frame_number\"], len(vid)):\n",
    "            e = equation[pivot]+str(frame[\"class\"])+' '\n",
    "            g = e.replace('÷', '/').replace('=','')\n",
    "            h = '{}{}'.format(e, eval(g))\n",
    "            equation[i] = h\n",
    "print(equation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ani_frame(vid, positions=positions, equation=equation, valid_boxes=valid_boxes, used_bb=used_bb, used_frame=used_frame)\n",
    "vidi = pims.open(args.output)\n",
    "#print(vidi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
